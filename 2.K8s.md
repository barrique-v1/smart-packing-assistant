# Kubernetes Deployment Guide (Docker Desktop)

This guide explains how to deploy the **Smart Packing Assistant with RAG (Retrieval-Augmented Generation)** to Kubernetes using **Docker Desktop's built-in Kubernetes cluster**.

## Additional Prerequisites to Docker Setup

- **kubectl** installed (usually comes with Docker Desktop)
- **Configured .env file** with your OpenAI API key (see `.env.example`)

**Note**: This guide uses an automated script (`./scripts/create-k8s-secrets.sh`) to generate Kubernetes secrets from your `.env` file.

---

## Quick Start

### 1. Enable Kubernetes in Docker Desktop

**macOS** & **Windows**:
1. Click Docker icon in menu bar â†’ **Settings** (gear icon)
2. Navigate to **Kubernetes** tab
3. **Enable Kubernetes**
4. Click **Apply & Install**
5. Wait 2-3 minutes for Kubernetes to initialize

**Verify Kubernetes is running**:

Check context (should show docker-desktop)
```bash
  kubectl config current-context
```
Expected Output: docker-desktop

Verify cluster info
```bash 
  kubectl cluster-info
```
Output: Kubernetes control plane is running at https://kubernetes.docker.internal:6443

### 2. Set Up Secrets from .env

Ensure your `.env` file is configured with your OpenAI API key and database credentials:
```bash
# Check .env exists
cat .env
```

Expected content:
```
OPENAI_API_KEY=sk-your-actual-openai-api-key
POSTGRES_DB=packing_assistant
POSTGRES_USER=admin
POSTGRES_PASSWORD=secret123
```

**Create Kubernetes secrets automatically** using the helper script:
```bash
# Run the automated secret creation script
./scripts/create-k8s-secrets.sh
```

This script will:
- Validate your `.env` file
- Create the `packing-assistant` namespace (if needed)
- Create the `app-secrets` secret with your credentials

**Alternative: Manual approach** (if you prefer):
```bash
source .env
kubectl apply -f k8s/00-namespace.yaml
kubectl create secret generic app-secrets \
  --namespace=packing-assistant \
  --from-literal=postgres-db="$POSTGRES_DB" \
  --from-literal=postgres-user="$POSTGRES_USER" \
  --from-literal=postgres-password="$POSTGRES_PASSWORD" \
  --from-literal=openai-api-key="$OPENAI_API_KEY" \
  --dry-run=client -o yaml | kubectl apply -f -
```

### 3. Build Docker Images and Pull Dependencies

**Build application images**:
```bash
  docker compose build
```

**Pull required base images** (for services and init containers):
```bash
  docker pull postgres:15-alpine
  docker pull qdrant/qdrant:v1.7.4
  docker pull busybox:1.36
```

**Verify images exist**:
```bash
  docker images | grep -E "smart-packing|postgres|qdrant|busybox"
```

**Expected output**:
```
smart-packing-assistant-api-gateway    latest    abc123    2 minutes ago    400MB
smart-packing-assistant-ai-worker      latest    def456    2 minutes ago    380MB
postgres                               15-alpine xxx        2 weeks ago        238MB
qdrant/qdrant                          v1.7.4    yyy        1 week ago         150MB
busybox                                1.36      zzz        5 days ago         2MB
```

### 4. Generate RAG Knowledge Base Embeddings

**Install Python dependencies**:
```bash
  pip3 install openai tqdm
```

**Generate embeddings** (creates vector representations of 140 packing items):
```bash
  python3 scripts/generate-embeddings.py
```

The script automatically reads your OpenAI API key from the `.env` file - no manual export needed!

**Expected output**:
```
======================================================================
  Smart Packing Assistant - Embedding Generation
======================================================================
âœ… OpenAI API key found (starts with 'sk-proj-NG...')
ğŸ“– Loading knowledge base from data/packing-knowledge.csv...
âœ… Loaded 140 items from knowledge base

ğŸ¤– Generating embeddings for 140 items...
   Model: text-embedding-3-small (1536 dimensions)

âœ… Generated 140 embeddings successfully
ğŸ’¾ Saving embeddings to data/packing-embeddings.json...
âœ… Saved 140 points to data/packing-embeddings.json
   File size: 6.28 MB
```

This step is **required** for RAG functionality. The embeddings file will be imported to Qdrant later.

### 5. Deploy to Kubernetes



**Deploy all services in order**:

```bash
# Deploy PostgreSQL (database for sessions/lists)
  kubectl apply -f k8s/02-postgres-pvc.yaml
  kubectl apply -f k8s/03-postgres-deployment.yaml
  kubectl apply -f k8s/04-postgres-service.yaml
  kubectl wait --for=condition=ready pod -l app=postgres -n packing-assistant --timeout=120s


# Step 3: Deploy Qdrant (vector database for RAG)
  kubectl apply -f k8s/11-qdrant-pvc.yaml
  kubectl apply -f k8s/12-qdrant-deployment.yaml
  kubectl apply -f k8s/13-qdrant-service.yaml
  kubectl wait --for=condition=ready pod -l app=qdrant -n packing-assistant --timeout=120s

# Step 4: Deploy AI Worker (GPT-4 + RAG)
  kubectl apply -f k8s/05-ai-worker-deployment.yaml
  kubectl apply -f k8s/06-ai-worker-service.yaml
  kubectl wait --for=condition=ready pod -l app=ai-worker -n packing-assistant --timeout=120s

# Step 5: Deploy API Gateway (REST API)
  kubectl apply -f k8s/07-api-gateway-deployment.yaml
  kubectl apply -f k8s/08-api-gateway-service.yaml
  kubectl wait --for=condition=ready pod -l app=api-gateway -n packing-assistant --timeout=120s

# Step 6: Deploy Frontend
  kubectl apply -f k8s/09-frontend-deployment.yaml
  kubectl apply -f k8s/10-frontend-service.yaml
  kubectl wait --for=condition=ready pod -l app=frontend -n packing-assistant --timeout=120s
```

### 6. Import RAG Knowledge Base to Qdrant

**Run port-forward in background and import embeddings**:
```bash
  # Start port forwarding in background
  kubectl port-forward -n packing-assistant service/qdrant 6333:6333 &

  # Wait for port-forward to be ready
  sleep 5

  # Import embeddings
  python3 scripts/import-to-qdrant.py --recreate

  # Cleanup port-forward
  pkill -f "port-forward.*qdrant"
```

**Expected output**:
```
======================================================================
  Smart Packing Assistant - Qdrant Import
======================================================================
ğŸ“– Loading embeddings from data/packing-embeddings.json...
âœ… Loaded 140 points from file
   Model: text-embedding-3-small
   Dimensions: 1536

ğŸ” Checking Qdrant connection at http://localhost:6333...
âœ… Qdrant is healthy and accessible

ğŸ”§ Creating collection 'packing_knowledge'...
âœ… Collection 'packing_knowledge' created successfully
   Vector size: 1536
   Distance metric: Cosine

ğŸ“¤ Uploading 140 points to Qdrant...
âœ… Successfully uploaded 140 points

âœ”ï¸  Verifying import...
   Points in collection: 140
   Vectors in collection: 140
âœ… Import verified successfully - all 140 points imported

ğŸ” Testing search with sample query...
   Query item: Passport
   Top 5 results:
      1. Passport (documents) - score: 1.0000
      2. Visa Documentation (documents) - score: 0.8316
      3. Travel Insurance Documents (documents) - score: 0.7739
```

### 7. Verify Deployment

Check all pods are running:
```bash
  kubectl get pods -n packing-assistant
```

Expected output (after 60-90 seconds):
```
NAME                           READY   STATUS    RESTARTS   AGE
postgres-xxx                   1/1     Running   0          3m
qdrant-xxx                     1/1     Running   0          2m
ai-worker-xxx                  1/1     Running   0          2m
api-gateway-xxx                1/1     Running   0          1m
frontend-xxx                   1/1     Running   0          1m
```

Check services:
```bash
  kubectl get services -n packing-assistant
```

Expected output:
```
NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
postgres      ClusterIP   10.96.x.x       <none>        5432/TCP         3m
qdrant        ClusterIP   10.96.x.x       <none>        6333/TCP         2m
ai-worker     ClusterIP   10.96.x.x       <none>        8081/TCP         2m
api-gateway   NodePort    10.96.x.x       <none>        8080:30080/TCP   1m
frontend      NodePort    10.96.x.x       <none>        80:30173/TCP     1m
```

### 8. Access and Test the Application

**Set up port forwarding** (macOS):

Frontend (access the UI):
```bash
  kubectl port-forward -n packing-assistant service/frontend 5173:80
```

API Gateway (for testing API endpoints):
```bash
  kubectl port-forward -n packing-assistant service/api-gateway 8080:8080
```

**Test health endpoint**:
```bash
  curl http://localhost:8080/api/packing/health
```
Expected: `{"status":"UP"}`

### 9. **Access the Frontend UI**

Go To [http://localhost:5173](http://localhost:5173) in your browser to access the Smart Packing Assistant UI.

### Happy packing! :)

## Architecture in Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker Desktop Kubernetes Cluster                           â”‚
â”‚   Context: docker-desktop                                     â”‚
â”‚                                                               â”‚
â”‚   Namespace: packing-assistant                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚  Secret: app-secrets                           â”‚          â”‚
â”‚   â”‚  - postgres-db, postgres-user, postgres-pass   â”‚          â”‚
â”‚   â”‚  - openai-api-key (for AI Worker)              â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚ PostgreSQL      â”‚  â”‚ PVC (1Gi)        â”‚                   â”‚
â”‚   â”‚ Deployment      â”‚â†â”€â”‚ Persistent       â”‚                   â”‚
â”‚   â”‚ Port: 5432      â”‚  â”‚ Storage          â”‚                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚          â†‘                                                    â”‚
â”‚   Service: postgres (ClusterIP)                               â”‚
â”‚          â†‘                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ API Gateway Deployment                   â”‚                â”‚
â”‚   â”‚ Port: 8080                               â”‚                â”‚
â”‚   â”‚ - Session management                     â”‚                â”‚
â”‚   â”‚ - REST API endpoints                     â”‚                â”‚
â”‚   â”‚ - Database persistence                   â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚          â†“                          â†“                         â”‚
â”‚   Service: api-gateway      HTTP â†’ AI Worker                  â”‚
â”‚   (NodePort: 30080)                 Deployment                â”‚
â”‚                                     Port: 8081                â”‚
â”‚                                     - GPT-4 integration       â”‚
â”‚                                     - RAG pipeline            â”‚
â”‚                                            â†“                  â”‚
â”‚                                     Service: qdrant           â”‚
â”‚                                     (ClusterIP)               â”‚
â”‚                                            â†“                  â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚ Qdrant Deployment   â”‚          â”‚
â”‚                              â”‚ Port: 6333          â”‚          â”‚
â”‚                              â”‚ - Vector search     â”‚          â”‚
â”‚                              â”‚ - 140 embeddings    â”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚    
â”‚                                     â†“                         â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                              â”‚ PVC (500Mi)      â”‚             â”‚
â”‚                              â”‚ Vector storage   â”‚             â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚    
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“                              â†“
    localhost:8080                  OpenAI API
    (via port-forward)              (GPT-4 + embeddings)
```

---

## RAG System Architecture

The RAG (Retrieval-Augmented Generation) pipeline enhances AI responses:

**5-Stage RAG Pipeline**:
1. **Vector Search**: Converts user query â†’ 1536-dim embedding â†’ searches Qdrant with filters
2. **Contextual Data**: Fetches weather info + culture tips
3. **Enhanced Prompt**: Combines retrieved items + context â†’ sends to GPT-4
4. **GPT Generation**: Creates packing list grounded in expert knowledge
5. **Response Validation**: Validates and returns structured JSON


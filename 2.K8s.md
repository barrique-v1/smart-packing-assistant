# Kubernetes Deployment Guide (Docker Desktop)

This guide explains how to deploy the **Smart Packing Assistant with RAG (Retrieval-Augmented Generation)** to Kubernetes using **Docker Desktop's built-in Kubernetes cluster**.

## Additional Prerequisites to Docker Setup

- **kubectl** installed (usually comes with Docker Desktop)

---

## Quick Start

### 1. Enable Kubernetes in Docker Desktop

**macOS**:
1. Click Docker icon in menu bar â†’ **Settings** (gear icon)
2. Navigate to **Kubernetes** tab
3. Check â˜‘ï¸ **Enable Kubernetes**
4. Click **Apply & Restart**
5. Wait 2-3 minutes for Kubernetes to initialize

**Windows**:
1. Right-click Docker icon in system tray â†’ **Settings**
2. Go to **Kubernetes** tab
3. Check â˜‘ï¸ **Enable Kubernetes**
4. Click **Apply & Restart**
5. Wait 2-3 minutes for initialization

**Verify Kubernetes is running**:

Check context (should show docker-desktop)
```bash
  kubectl config current-context
```
Output: docker-desktop

Verify cluster info
```bash 
  kubectl cluster-info
```
Output: Kubernetes control plane is running at https://kubernetes.docker.internal:6443

### 2. Set Up OpenAI API Key

Update the secret file with your API key:
```bash
  echo -n "sk-your-actual-openai-key" | base64
```

Copy the output and update `k8s/01-postgres-secret.yaml` - replace the placeholder `openai-api-key` value.

### 3. Build Docker Images

From project root:
```bash
  docker compose build
```

Verify images exist:
```bash
  docker images | grep smart-packing
```

**Expected output**:
```
smart-packing-assistant-api-gateway    latest    abc123    2 minutes ago    400MB
smart-packing-assistant-ai-worker      latest    def456    2 minutes ago    380MB
smart-packing-assistant-qdrant         latest    ghi789    2 minutes ago    150MB
```

### 4. Generate RAG Knowledge Base Embeddings

**Install Python dependencies**:
```bash
  pip3 install openai tqdm
```

**Set environment variable**:
```bash
  export OPENAI_API_KEY=sk-your-actual-openai-key
```

**Generate embeddings** (creates vector representations of 140 packing items):
```bash
  python3 scripts/generate-embeddings.py
```

**Expected output**:
```
======================================================================
  Smart Packing Assistant - Embedding Generation
======================================================================
âœ… OpenAI API key found (starts with 'sk-proj-NG...')
ğŸ“– Loading knowledge base from data/packing-knowledge.csv...
âœ… Loaded 140 items from knowledge base

ğŸ¤– Generating embeddings for 140 items...
   Model: text-embedding-3-small (1536 dimensions)

âœ… Generated 140 embeddings successfully
ğŸ’¾ Saving embeddings to data/packing-embeddings.json...
âœ… Saved 140 points to data/packing-embeddings.json
   File size: 6.28 MB
```

This step is **required** for RAG functionality. The embeddings file will be imported to Qdrant later.

### 5. Deploy to Kubernetes

**Deploy all services in order**:

**Step 1: Create namespace and secrets**
```bash
  kubectl apply -f k8s/00-namespace.yaml
  kubectl apply -f k8s/01-postgres-secret.yaml
```

**Step 2: Deploy PostgreSQL** (database for sessions/lists)
```bash
  kubectl apply -f k8s/02-postgres-pvc.yaml
  kubectl apply -f k8s/03-postgres-deployment.yaml
  kubectl apply -f k8s/04-postgres-service.yaml
  kubectl wait --for=condition=ready pod -l app=postgres -n packing-assistant --timeout=120s
```

**Step 3: Deploy Qdrant** (vector database for RAG)
```bash
  kubectl apply -f k8s/11-qdrant-pvc.yaml
  kubectl apply -f k8s/12-qdrant-deployment.yaml
  kubectl apply -f k8s/13-qdrant-service.yaml
  kubectl wait --for=condition=ready pod -l app=qdrant -n packing-assistant --timeout=120s
```

**Step 4: Deploy AI Worker** (GPT-4 + RAG)
```bash
  kubectl apply -f k8s/05-ai-worker-deployment.yaml
  kubectl apply -f k8s/06-ai-worker-service.yaml
  kubectl wait --for=condition=ready pod -l app=ai-worker -n packing-assistant --timeout=120s
```

**Step 5: Deploy API Gateway** (REST API)
```bash
  kubectl apply -f k8s/07-api-gateway-deployment.yaml
  kubectl apply -f k8s/08-api-gateway-service.yaml
  kubectl wait --for=condition=ready pod -l app=api-gateway -n packing-assistant --timeout=120s
```

**Step 6: Deploy Frontend**
```bash
  kubectl apply -f k8s/09-frontend-deployment.yaml
  kubectl apply -f k8s/10-frontend-service.yaml
  kubectl wait --for=condition=ready pod -l app=frontend -n packing-assistant --timeout=120s
```

### 6. Import RAG Knowledge Base to Qdrant

**Install Python dependency**:
```bash
  pip3 install requests
```

**Set up port forwarding** (in a new terminal window):
```bash
  kubectl port-forward -n packing-assistant service/qdrant 6333:6333
```

**Import embeddings** (in another terminal):
```bash
  python3 scripts/import-to-qdrant.py --recreate
```

**Expected output**:
```
======================================================================
  Smart Packing Assistant - Qdrant Import
======================================================================
ğŸ“– Loading embeddings from data/packing-embeddings.json...
âœ… Loaded 140 points from file
   Model: text-embedding-3-small
   Dimensions: 1536

ğŸ” Checking Qdrant connection at http://localhost:6333...
âœ… Qdrant is healthy and accessible

ğŸ”§ Creating collection 'packing_knowledge'...
âœ… Collection 'packing_knowledge' created successfully
   Vector size: 1536
   Distance metric: Cosine

ğŸ“¤ Uploading 140 points to Qdrant...
âœ… Successfully uploaded 140 points

âœ”ï¸  Verifying import...
   Points in collection: 140
   Vectors in collection: 140
âœ… Import verified successfully - all 140 points imported

ğŸ” Testing search with sample query...
   Query item: Passport
   Top 5 results:
      1. Passport (documents) - score: 1.0000
      2. Visa Documentation (documents) - score: 0.8316
      3. Travel Insurance Documents (documents) - score: 0.7739
```

**Close the port-forward** (Ctrl+C in the terminal running port-forward).

### 7. Verify Deployment

Check all pods are running:
```bash
  kubectl get pods -n packing-assistant
```

Expected output (after 60-90 seconds):
```
NAME                           READY   STATUS    RESTARTS   AGE
postgres-xxx                   1/1     Running   0          3m
qdrant-xxx                     1/1     Running   0          2m
ai-worker-xxx                  1/1     Running   0          2m
api-gateway-xxx                1/1     Running   0          1m
frontend-xxx                   1/1     Running   0          1m
```

Check services:
```bash
  kubectl get services -n packing-assistant
```

Expected output:
```
NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
postgres      ClusterIP   10.96.x.x       <none>        5432/TCP         3m
qdrant        ClusterIP   10.96.x.x       <none>        6333/TCP         2m
ai-worker     ClusterIP   10.96.x.x       <none>        8081/TCP         2m
api-gateway   NodePort    10.96.x.x       <none>        8080:30080/TCP   1m
frontend      NodePort    10.96.x.x       <none>        80:30081/TCP     1m
```

### 8. Access and Test the Application

**Set up port forwarding** (macOS):

Frontend (when you want to access the UI):
```bash
  kubectl port-forward -n packing-assistant service/frontend 5173:80
```

API Gateway (for testing API endpoints):
```bash
  kubectl port-forward -n packing-assistant service/api-gateway 8080:8080
```

**Test health endpoint**:
```bash
  curl http://localhost:8080/api/packing/health
```
Expected: `{"status":"UP"}`

**Create a session**:
```bash
SESSION_RESPONSE=$(curl -s -X POST http://localhost:8080/api/sessions)
echo $SESSION_RESPONSE
```
Expected: `{"sessionToken":"abc123...","sessionId":"uuid-here"}`

Extract token (macOS/Linux with jq):
```bash
TOKEN=$(echo $SESSION_RESPONSE | jq -r '.sessionToken')
echo "Token: $TOKEN"
```
Or copy the token manually from the output.

**Generate packing list with RAG** (Tokyo Summer Vacation):
```bash
curl -X POST http://localhost:8080/api/packing/generate \
  -H "Content-Type: application/json" \
  -H "X-Session-Token: $TOKEN" \
  -d '{
    "destination": "Tokyo",
    "durationDays": 7,
    "season": "SUMMER",
    "travelType": "VACATION"
  }' | jq '.'
```

**Verify RAG is working** - Check AI Worker logs:
```bash
kubectl logs -n packing-assistant deployment/ai-worker --tail=30 | grep "Retrieved items"
```

**Test Business Trip** (New York Winter Business):
```bash
curl -X POST http://localhost:8080/api/packing/generate \
  -H "Content-Type: application/json" \
  -H "X-Session-Token: $TOKEN" \
  -d '{
    "destination": "New York",
    "durationDays": 3,
    "season": "WINTER",
    "travelType": "BUSINESS"
  }' | jq '.'
```

**Expected**: Business-specific items like:
- Business Suit, Dress Shirts, Formal Shoes
- Laptop, Briefcase, Business Cards
- Winter Coat, Thermal Underwear, Gloves

---

## Architecture in Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker Desktop Kubernetes Cluster                           â”‚
â”‚   Context: docker-desktop                                     â”‚
â”‚                                                                â”‚
â”‚   Namespace: packing-assistant                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚  Secret: app-secrets                           â”‚         â”‚
â”‚   â”‚  - postgres-db, postgres-user, postgres-pass   â”‚         â”‚
â”‚   â”‚  - openai-api-key (for AI Worker)              â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ PostgreSQL      â”‚  â”‚ PVC (1Gi)        â”‚                 â”‚
â”‚   â”‚ Deployment      â”‚â†â”€â”‚ Persistent       â”‚                 â”‚
â”‚   â”‚ Port: 5432      â”‚  â”‚ Storage          â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚          â†‘                                                     â”‚
â”‚   Service: postgres (ClusterIP)                               â”‚
â”‚          â†‘                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚ API Gateway Deployment                   â”‚               â”‚
â”‚   â”‚ Port: 8080                               â”‚               â”‚
â”‚   â”‚ - Session management                     â”‚               â”‚
â”‚   â”‚ - REST API endpoints                     â”‚               â”‚
â”‚   â”‚ - Database persistence                   â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚          â†“                          â†“                         â”‚
â”‚   Service: api-gateway      HTTP â†’ AI Worker                 â”‚
â”‚   (NodePort: 30080)                 Deployment               â”‚
â”‚                                     Port: 8081               â”‚
â”‚                                     - GPT-4 integration      â”‚
â”‚                                     - RAG pipeline           â”‚
â”‚                                            â†“                  â”‚
â”‚                                     Service: qdrant          â”‚
â”‚                                     (ClusterIP)              â”‚
â”‚                                            â†“                  â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                              â”‚ Qdrant Deployment   â”‚         â”‚
â”‚                              â”‚ Port: 6333          â”‚         â”‚
â”‚                              â”‚ - Vector search     â”‚         â”‚
â”‚                              â”‚ - 140 embeddings    â”‚         â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                     â†“                         â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                              â”‚ PVC (500Mi)      â”‚            â”‚
â”‚                              â”‚ Vector storage   â”‚            â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“                              â†“
    localhost:8080                  OpenAI API
    (via port-forward)              (GPT-4 + embeddings)
```

---

## RAG System Architecture

The RAG (Retrieval-Augmented Generation) pipeline enhances AI responses:

**5-Stage RAG Pipeline**:
1. **Vector Search**: Converts user query â†’ 1536-dim embedding â†’ searches Qdrant with filters
2. **Contextual Data**: Fetches weather info + culture tips
3. **Enhanced Prompt**: Combines retrieved items (up to 20) + context â†’ sends to GPT-4
4. **GPT Generation**: Creates packing list grounded in expert knowledge
5. **Response Validation**: Validates and returns structured JSON

**Knowledge Base**:
- **140 expert-curated items** covering:
  - Universal essentials (passport, chargers, hygiene)
  - Business travel (suits, laptop, business cards)
  - Beach/tropical (swimsuit, sunscreen, snorkel gear)
  - Mountain/adventure (hiking boots, camping gear)
  - Arctic/cold weather (thermal layers, winter gear)

**Performance Metrics**:
- Vector Search: 400-1200ms
- GPT Generation: 9-12 seconds
- Total Response Time: ~10-13 seconds
- Items Retrieved per query: 20 (top-K limit)
- Similarity Threshold: 0.40 (scores typically 0.40-0.65)

---

## Common Commands

### Update Kubernetes Pods

```bash
  docker compose build && kubectl rollout restart deployment --all -n
  packing-assistant
```


### Deployment Management

Apply all manifests at once:
```bash
kubectl apply -f k8s/
```

Delete all resources (keeps PVC data):
```bash
kubectl delete -f k8s/ --ignore-not-found=true
```

Update specific deployment:
```bash
kubectl apply -f k8s/07-api-gateway-deployment.yaml
```

Restart a deployment (rolling restart):
```bash
kubectl rollout restart deployment/api-gateway -n packing-assistant
kubectl rollout restart deployment/ai-worker -n packing-assistant
```

Check rollout status:
```bash
kubectl rollout status deployment/api-gateway -n packing-assistant
```

Scale deployment:
```bash
kubectl scale deployment/ai-worker --replicas=2 -n packing-assistant
```

### Monitoring & Debugging

Watch pods (live updates):
```bash
kubectl get pods -n packing-assistant --watch
```

Get detailed pod info:
```bash
kubectl describe pod <pod-name> -n packing-assistant
```

View logs:
```bash
kubectl logs deployment/api-gateway -n packing-assistant --tail=50
kubectl logs deployment/ai-worker -n packing-assistant --tail=50
kubectl logs deployment/qdrant -n packing-assistant --tail=50
```

Follow logs (live tail):
```bash
kubectl logs -f deployment/ai-worker -n packing-assistant
```

Execute commands in pod:
```bash
kubectl exec -it deployment/postgres -n packing-assistant -- psql -U admin -d packing_assistant
kubectl exec -it deployment/qdrant -n packing-assistant -- /bin/sh
```

### Port Forwarding

Frontend (access UI):
```bash
kubectl port-forward -n packing-assistant service/frontend 5173:80
```

API Gateway (required for testing):
```bash
kubectl port-forward -n packing-assistant service/api-gateway 8080:8080
```

AI Worker (for direct testing):
```bash
kubectl port-forward -n packing-assistant service/ai-worker 8081:8081
```

Qdrant (for knowledge base management):
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333
```

PostgreSQL (for database access):
```bash
kubectl port-forward -n packing-assistant service/postgres 5432:5432
```

### RAG-Specific Commands

Check Qdrant collection status:
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333 &
curl http://localhost:6333/collections/packing_knowledge | jq '.'
```

Verify embeddings count (expected: 140):
```bash
curl http://localhost:6333/collections/packing_knowledge | jq '.result.points_count'
```

Test vector search directly:
```bash
python3 << 'EOF'
import requests
response = requests.get('http://localhost:6333/collections/packing_knowledge')
print(f"Status: {response.json()['result']['status']}")
print(f"Vectors: {response.json()['result']['vectors_count']}")
EOF
```

Check AI Worker can connect to Qdrant:
```bash
kubectl exec -it deployment/ai-worker -n packing-assistant -- wget -qO- http://qdrant:6333/collections/packing_knowledge
```

Reimport knowledge base (if needed):
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333
python3 scripts/import-to-qdrant.py --recreate
```

---

## Troubleshooting

### 1. RAG Not Working (0 Retrieved Items)

**Symptoms**: AI Worker logs show:
```
Retrieved items: 0
âš ï¸ Vector search returned no items - falling back to pure GPT
```

**Solutions**:

1. Verify Qdrant has embeddings (should show: 140):
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333
curl http://localhost:6333/collections/packing_knowledge | jq '.result.points_count'
```

2. Check if collection exists (should show: `[{"name": "packing_knowledge"}]`):
```bash
curl http://localhost:6333/collections | jq '.result.collections'
```

3. Reimport embeddings if missing:
```bash
python3 scripts/import-to-qdrant.py --recreate
```

4. Restart AI Worker after reimport:
```bash
kubectl rollout restart deployment/ai-worker -n packing-assistant
```

5. Check AI Worker logs for vector search (should show: "âœ“ Vector search completed in XXms - found 20 items"):
```bash
kubectl logs deployment/ai-worker -n packing-assistant --tail=50 | grep "Vector search"
```

### 2. Qdrant Pod Not Starting

**Symptoms**:
```
NAME                  READY   STATUS             RESTARTS   AGE
qdrant-xxx            0/1     CrashLoopBackOff   3          2m
```

**Solutions**:

1. Check Qdrant logs:
```bash
kubectl logs deployment/qdrant -n packing-assistant
```

2. Verify PVC is bound (status should be: Bound):
```bash
kubectl get pvc -n packing-assistant | grep qdrant
```

3. Check storage class:
```bash
kubectl get pvc qdrant-pvc -n packing-assistant -o yaml | grep storageClassName
```

4. Recreate PVC if needed:
```bash
kubectl delete pvc qdrant-pvc -n packing-assistant
kubectl apply -f k8s/11-qdrant-pvc.yaml
```

5. Restart Qdrant:
```bash
kubectl rollout restart deployment/qdrant -n packing-assistant
```

### 3. Embeddings Generation Failed

**Symptoms**:
```
âŒ Error: OPENAI_API_KEY environment variable not set
```

**Solutions**:

1. Check API key is set (should show: sk-proj-...):
```bash
echo $OPENAI_API_KEY
```

2. Export API key:
```bash
export OPENAI_API_KEY=sk-your-actual-key
```

3. Or read from .env file:
```bash
export OPENAI_API_KEY=$(grep OPENAI_API_KEY .env | cut -d '=' -f2)
```

4. Regenerate embeddings:
```bash
python3 scripts/generate-embeddings.py
```

5. Verify output file exists (should show: ~6.3 MB file):
```bash
ls -lh data/packing-embeddings.json
```

### 4. AI Worker Can't Connect to Qdrant

**Symptoms**: AI Worker logs show:
```
Vector search failed: Connection refused to qdrant:6333
```

**Solutions**:

1. Check Qdrant service exists:
```bash
kubectl get svc qdrant -n packing-assistant
```

2. Test DNS resolution from AI Worker (should resolve to: qdrant.packing-assistant.svc.cluster.local):
```bash
kubectl exec -it deployment/ai-worker -n packing-assistant -- nslookup qdrant
```

3. Check Qdrant is accessible within cluster:
```bash
kubectl run test --image=curlimages/curl --rm -it --restart=Never -n packing-assistant -- \
  curl -s http://qdrant:6333/collections
```

4. Verify Qdrant pod is running (status should be: Running):
```bash
kubectl get pods -n packing-assistant | grep qdrant
```

5. Check Qdrant port (should show: port: 6333):
```bash
kubectl get svc qdrant -n packing-assistant -o yaml | grep port
```

### 5. Import Script Fails

**Symptoms**:
```
Cannot connect to Qdrant: Connection refused
```

**Solutions**:

1. Ensure port-forward is running:
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333
```

2. Test connection (expected: OK):
```bash
curl http://localhost:6333/healthz
```

3. Check if another process is using port 6333:
```bash
lsof -i :6333
```

4. Use different port for port-forward if needed:
```bash
kubectl port-forward -n packing-assistant service/qdrant 6334:6333
python3 scripts/import-to-qdrant.py --qdrant-url http://localhost:6334
```

5. Verify embeddings file exists:
```bash
ls -lh data/packing-embeddings.json
```

### 6. OpenAI API Key Not Working

**Symptoms**: AI Worker logs show:
```
401 Unauthorized: Incorrect API key provided
```

**Solutions**:

1. Verify API key in secret (should show: sk-proj-...):
```bash
kubectl get secret app-secrets -n packing-assistant -o jsonpath='{.data.openai-api-key}' | base64 -d
```

2. Update secret with correct key (copy output and update `k8s/01-postgres-secret.yaml`):
```bash
echo -n "sk-your-actual-key" | base64
```

3. Apply updated secret:
```bash
kubectl apply -f k8s/01-postgres-secret.yaml
```

4. Restart AI Worker to pick up new secret:
```bash
kubectl rollout restart deployment/ai-worker -n packing-assistant
```

5. Verify AI Worker logs (should show: "âœ“ OpenAI API key configured"):
```bash
kubectl logs deployment/ai-worker -n packing-assistant --tail=20 | grep "OpenAI"
```

### 7. API Gateway Timeout When Generating Packing Lists

**Symptoms**: API Gateway logs show:
```
HttpTimeoutException: Request cancelled
I/O error on POST request for "http://ai-worker:8081/api/ai/generate"
```

**Cause**: The AI Worker takes 30-45 seconds to generate responses (OpenAI API + vector search). If the API Gateway timeout is too short, requests are cancelled.

**Solutions**:

1. Check current timeout in `RestTemplateConfig.kt` - should be at least 90 seconds:
```kotlin
.readTimeout(Duration.ofSeconds(90))
```

2. If you updated the file, rebuild and redeploy:
```bash
docker compose build api-gateway
kubectl rollout restart deployment/api-gateway -n packing-assistant
```

3. Verify AI Worker response times in logs (expected: "Packing list generated successfully in 35000ms"):
```bash
kubectl logs deployment/ai-worker -n packing-assistant --tail=50 | grep "generated successfully"
```

### 8. Database Connection Errors

**Symptoms**: API Gateway logs show:
```
Connection to postgres:5432 refused
```

**Solutions**:

1. Check PostgreSQL pod is running:
```bash
kubectl get pods -n packing-assistant | grep postgres
```

2. Test PostgreSQL from within cluster:
```bash
kubectl exec -it deployment/postgres -n packing-assistant -- \
  psql -U admin -d packing_assistant -c "SELECT 1;"
```

3. Check PostgreSQL service:
```bash
kubectl get svc postgres -n packing-assistant
```

4. Verify secrets are correct:
```bash
kubectl get secret app-secrets -n packing-assistant -o jsonpath='{.data.postgres-password}' | base64 -d
```

5. Check API Gateway environment variables:
```bash
kubectl exec -it deployment/api-gateway -n packing-assistant -- env | grep POSTGRES
```

---

## End-to-End Testing with RAG

### Complete Test Flow

**Step 1: Verify all pods are ready**
```bash
kubectl get pods -n packing-assistant
```
Expected: All pods Running with READY 1/1

**Step 2: Verify Qdrant has knowledge base** (expected: 140)
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333 &
sleep 2
curl -s http://localhost:6333/collections/packing_knowledge | jq '.result.points_count'
```

**Step 3: Set up API Gateway port-forward**
```bash
kubectl port-forward -n packing-assistant service/api-gateway 8080:8080 &
sleep 2
```

**Step 4: Test health endpoints** (expected: `{"status":"UP"}`)
```bash
curl http://localhost:8080/actuator/health
```

**Step 5: Create session**
```bash
SESSION_RESPONSE=$(curl -s -X POST http://localhost:8080/api/sessions)
echo $SESSION_RESPONSE
TOKEN=$(echo $SESSION_RESPONSE | jq -r '.sessionToken')
echo "Session Token: $TOKEN"
```

**Step 6: Generate Tokyo vacation packing list** (RAG test)
```bash
curl -s -X POST http://localhost:8080/api/packing/generate \
  -H "Content-Type: application/json" \
  -H "X-Session-Token: $TOKEN" \
  -d '{
    "destination": "Tokyo",
    "durationDays": 7,
    "season": "SUMMER",
    "travelType": "VACATION"
  }' | jq '.categories | keys'
```
Expected: `["clothing", "documents", "hygiene", "other", "tech"]`

**Step 7: Verify RAG retrieval in logs** (expected: "Retrieved items: 20, Weather: true, Culture tips: 3")
```bash
kubectl logs deployment/ai-worker -n packing-assistant --tail=30 | grep "Retrieved items"
```

**Step 8: Test business trip** (different RAG results)
```bash
curl -s -X POST http://localhost:8080/api/packing/generate \
  -H "Content-Type: application/json" \
  -H "X-Session-Token: $TOKEN" \
  -d '{
    "destination": "New York",
    "durationDays": 3,
    "season": "WINTER",
    "travelType": "BUSINESS"
  }' | jq '.categories.clothing[:3]'
```
Expected: Business items like suits, dress shirts, formal shoes

**Step 9: Verify database persistence**
```bash
kubectl exec -it deployment/postgres -n packing-assistant -- \
  psql -U admin -d packing_assistant -c \
  "SELECT destination, travel_type FROM packing_lists ORDER BY created_at DESC LIMIT 2;"
```
Expected: Tokyo (VACATION) and New York (BUSINESS)

**Step 10: Cleanup port-forwards**
```bash
pkill -f "port-forward.*packing-assistant"
```

### RAG Performance Testing

Test vector search performance:
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333 &
```

Run the performance test:
```bash
python3 << 'EOF'
import requests
import time
from openai import OpenAI
import os

client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])

# Generate test query embedding
start = time.time()
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=["Packing for beach vacation"],
    dimensions=1536
)
embedding_time = time.time() - start
print(f"Embedding generation: {embedding_time:.3f}s")

# Test vector search
start = time.time()
search_result = requests.post(
    'http://localhost:6333/collections/packing_knowledge/points/search',
    json={
        "vector": response.data[0].embedding,
        "limit": 20,
        "score_threshold": 0.40
    }
).json()
search_time = time.time() - start
print(f"Vector search: {search_time:.3f}s")
print(f"Items found: {len(search_result.get('result', []))}")
print(f"Top score: {search_result['result'][0]['score']:.3f}")
EOF
```

Cleanup:
```bash
pkill -f "port-forward.*packing-assistant"
```

---

## Resource Requirements

### Minimum Requirements
- **Memory**: 4 GB (6-8 GB recommended)
- **CPUs**: 2 cores (4 recommended)
- **Disk**: 20 GB free space

### Per-Service Resource Limits

| Service | Memory Request | Memory Limit | CPU Request | CPU Limit |
|---------|---------------|--------------|-------------|-----------|
| **PostgreSQL** | 256Mi | 512Mi | 250m | 500m |
| **Qdrant** | 256Mi | 512Mi | 200m | 500m |
| **AI Worker** | 512Mi | 1Gi | 250m | 500m |
| **API Gateway** | 512Mi | 1Gi | 250m | 500m |
| **Total** | ~1.5Gi | ~3Gi | 950m | 2 cores |

### Docker Desktop Settings (macOS)
1. Docker Desktop â†’ Settings â†’ Resources
2. Set **Memory** to 6 GB or 8 GB
3. Set **CPUs** to 4
4. Set **Disk image size** to 60 GB
5. Click **Apply & Restart**

---

## Quick Reference: Qdrant Operations

Check if Qdrant collection exists and has data (expected: `{"status": "green", "points": 140}`):
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333 &
curl -s http://localhost:6333/collections/packing_knowledge | jq '{status: .result.status, points: .result.points_count}'
```

Reimport knowledge base (if collection is missing or corrupted):
```bash
pip3 install requests tqdm
python3 scripts/import-to-qdrant.py --recreate
```

Access Qdrant Dashboard:
```bash
kubectl port-forward -n packing-assistant service/qdrant 6333:6333
```
Then open: http://localhost:6333/dashboard

Delete and recreate Qdrant data:
```bash
kubectl delete pvc qdrant-pvc -n packing-assistant
kubectl apply -f k8s/11-qdrant-pvc.yaml
kubectl rollout restart deployment/qdrant -n packing-assistant
```
Then reimport: `python3 scripts/import-to-qdrant.py --recreate`

---

## Cleanup

Delete All Resources (Keep Cluster)

Delete namespace (removes all resources):
```bash
kubectl delete namespace packing-assistant
```

Verify deletion:
```bash
kubectl get namespaces
```